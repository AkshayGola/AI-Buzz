{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "659ab242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "489637c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"letter-recognition.data.txt\", header = None)\n",
    "\n",
    "# X = df[df.columns[1:]]\n",
    "# Y = df[0]\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30, random_state = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96914492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5716</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.410256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.096154</td>\n",
       "      <td>-0.371795</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>-0.346154</td>\n",
       "      <td>0.339744</td>\n",
       "      <td>-0.211538</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.782051</td>\n",
       "      <td>-0.269231</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>-0.256410</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.237179</td>\n",
       "      <td>-0.141026</td>\n",
       "      <td>0.182390</td>\n",
       "      <td>-0.262821</td>\n",
       "      <td>-0.179487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.227848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>-0.234177</td>\n",
       "      <td>0.259494</td>\n",
       "      <td>-0.132911</td>\n",
       "      <td>0.284810</td>\n",
       "      <td>-0.132911</td>\n",
       "      <td>-0.063291</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.607595</td>\n",
       "      <td>-0.253165</td>\n",
       "      <td>-0.025316</td>\n",
       "      <td>-0.208861</td>\n",
       "      <td>-0.145570</td>\n",
       "      <td>-0.164557</td>\n",
       "      <td>-0.221519</td>\n",
       "      <td>-0.613924</td>\n",
       "      <td>-0.164557</td>\n",
       "      <td>0.367089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.364865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.195946</td>\n",
       "      <td>-0.216216</td>\n",
       "      <td>0.141892</td>\n",
       "      <td>-0.222973</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>-0.195946</td>\n",
       "      <td>-0.216216</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.844595</td>\n",
       "      <td>-0.290541</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>-0.263514</td>\n",
       "      <td>-0.074324</td>\n",
       "      <td>-0.189189</td>\n",
       "      <td>-0.135135</td>\n",
       "      <td>-0.810811</td>\n",
       "      <td>-0.155405</td>\n",
       "      <td>0.054054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.344371</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.192053</td>\n",
       "      <td>-0.165563</td>\n",
       "      <td>0.132450</td>\n",
       "      <td>-0.052980</td>\n",
       "      <td>0.238411</td>\n",
       "      <td>-0.019868</td>\n",
       "      <td>-0.066225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.735099</td>\n",
       "      <td>-0.324503</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>-0.278146</td>\n",
       "      <td>-0.112583</td>\n",
       "      <td>-0.211921</td>\n",
       "      <td>-0.158940</td>\n",
       "      <td>-0.794702</td>\n",
       "      <td>0.185430</td>\n",
       "      <td>-0.105960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.229814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.012422</td>\n",
       "      <td>-0.248447</td>\n",
       "      <td>0.223602</td>\n",
       "      <td>-0.149068</td>\n",
       "      <td>0.267081</td>\n",
       "      <td>-0.130435</td>\n",
       "      <td>-0.068323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.596273</td>\n",
       "      <td>-0.248447</td>\n",
       "      <td>-0.031056</td>\n",
       "      <td>-0.198758</td>\n",
       "      <td>-0.155280</td>\n",
       "      <td>-0.149068</td>\n",
       "      <td>-0.217391</td>\n",
       "      <td>-0.645963</td>\n",
       "      <td>-0.043478</td>\n",
       "      <td>0.267081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class         1    2         3         4         5         6         7  \\\n",
       "5716    0.0 -0.410256  0.0 -0.096154 -0.371795  0.205128 -0.346154  0.339744   \n",
       "1515    2.0 -0.227848  0.0  0.012658 -0.234177  0.259494 -0.132911  0.284810   \n",
       "363     2.0 -0.364865  0.0 -0.195946 -0.216216  0.141892 -0.222973  0.324324   \n",
       "415     2.0 -0.344371  0.0 -0.192053 -0.165563  0.132450 -0.052980  0.238411   \n",
       "1295    2.0 -0.229814  0.0 -0.012422 -0.248447  0.223602 -0.149068  0.267081   \n",
       "\n",
       "             8         9  ...        36        37        38        39  \\\n",
       "5716 -0.211538  0.044872  ... -0.782051 -0.269231  0.006410 -0.256410   \n",
       "1515 -0.132911 -0.063291  ... -0.607595 -0.253165 -0.025316 -0.208861   \n",
       "363  -0.195946 -0.216216  ... -0.844595 -0.290541  0.054054 -0.263514   \n",
       "415  -0.019868 -0.066225  ... -0.735099 -0.324503  0.006623 -0.278146   \n",
       "1295 -0.130435 -0.068323  ... -0.596273 -0.248447 -0.031056 -0.198758   \n",
       "\n",
       "            40        41        42        43        44        45  \n",
       "5716 -0.083333 -0.237179 -0.141026  0.182390 -0.262821 -0.179487  \n",
       "1515 -0.145570 -0.164557 -0.221519 -0.613924 -0.164557  0.367089  \n",
       "363  -0.074324 -0.189189 -0.135135 -0.810811 -0.155405  0.054054  \n",
       "415  -0.112583 -0.211921 -0.158940 -0.794702  0.185430 -0.105960  \n",
       "1295 -0.155280 -0.149068 -0.217391 -0.645963 -0.043478  0.267081  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'model/gesture_classifier/gesture_train_akshay.csv'\n",
    "#dataset = 'model/gesture_classifier/gesture_train_kailash.csv'\n",
    "\n",
    "column_names = ['class', '1', '2', '3', '4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45']\n",
    "\n",
    "X_column_names = ['1', '2', '3', '4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45']\n",
    "\n",
    "df = pd.read_csv(dataset, header = None, names=column_names)\n",
    "df = df.dropna(how='any')\n",
    "\n",
    "# Shuffling the dataset\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "74c53cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             1    2         3         4         5         6         7  \\\n",
      "5716 -0.410256  0.0 -0.096154 -0.371795  0.205128 -0.346154  0.339744   \n",
      "1515 -0.227848  0.0  0.012658 -0.234177  0.259494 -0.132911  0.284810   \n",
      "363  -0.364865  0.0 -0.195946 -0.216216  0.141892 -0.222973  0.324324   \n",
      "415  -0.344371  0.0 -0.192053 -0.165563  0.132450 -0.052980  0.238411   \n",
      "1295 -0.229814  0.0 -0.012422 -0.248447  0.223602 -0.149068  0.267081   \n",
      "...        ...  ...       ...       ...       ...       ...       ...   \n",
      "2923 -0.397351  0.0 -0.198675 -0.357616  0.258278 -0.364238  0.410596   \n",
      "661  -0.207101  0.0 -0.029586 -0.278107  0.201183 -0.112426  0.213018   \n",
      "5377 -0.371795  0.0 -0.173077 -0.384615  0.089744 -0.352564  0.269231   \n",
      "5203 -0.401274  0.0 -0.171975 -0.426752  0.089172 -0.363057  0.267516   \n",
      "4168 -0.241611  0.0 -0.214765 -0.315436  0.154362 -0.281879  0.322148   \n",
      "\n",
      "             8         9        10  ...        36        37        38  \\\n",
      "5716 -0.211538  0.044872 -0.455128  ... -0.782051 -0.269231  0.006410   \n",
      "1515 -0.132911 -0.063291 -0.436709  ... -0.607595 -0.253165 -0.025316   \n",
      "363  -0.195946 -0.216216 -0.506757  ... -0.844595 -0.290541  0.054054   \n",
      "415  -0.019868 -0.066225 -0.470199  ... -0.735099 -0.324503  0.006623   \n",
      "1295 -0.130435 -0.068323 -0.434783  ... -0.596273 -0.248447 -0.031056   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "2923 -0.218543  0.000000 -0.483444  ... -0.807947 -0.291391  0.033113   \n",
      "661  -0.112426 -0.076923 -0.384615  ... -0.609467 -0.236686 -0.023669   \n",
      "5377 -0.256410 -0.051282 -0.461538  ... -0.865385 -0.250000  0.025641   \n",
      "5203 -0.242038 -0.044586 -0.477707  ... -0.878981 -0.222930  0.025478   \n",
      "4168 -0.147651 -0.006711 -0.463087  ... -0.771812 -0.255034  0.013423   \n",
      "\n",
      "            39        40        41        42        43        44        45  \n",
      "5716 -0.256410 -0.083333 -0.237179 -0.141026  0.182390 -0.262821 -0.179487  \n",
      "1515 -0.208861 -0.145570 -0.164557 -0.221519 -0.613924 -0.164557  0.367089  \n",
      "363  -0.263514 -0.074324 -0.189189 -0.135135 -0.810811 -0.155405  0.054054  \n",
      "415  -0.278146 -0.112583 -0.211921 -0.158940 -0.794702  0.185430 -0.105960  \n",
      "1295 -0.198758 -0.155280 -0.149068 -0.217391 -0.645963 -0.043478  0.267081  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "2923 -0.271523 -0.086093 -0.231788 -0.139073 -0.225166 -0.039735 -0.125828  \n",
      "661  -0.183432 -0.147929 -0.118343 -0.218935 -0.727811  0.301775  0.100592  \n",
      "5377 -0.230769 -0.051282 -0.250000 -0.108974  0.147436 -0.339744 -0.141026  \n",
      "5203 -0.222930 -0.057325 -0.222930 -0.089172  0.132911 -0.382166 -0.082803  \n",
      "4168 -0.261745 -0.087248 -0.208054 -0.154362 -0.100671 -0.127517 -0.107383  \n",
      "\n",
      "[5940 rows x 45 columns]\n",
      "      class\n",
      "5716    0.0\n",
      "1515    2.0\n",
      "363     2.0\n",
      "415     2.0\n",
      "1295    2.0\n",
      "...     ...\n",
      "2923    1.0\n",
      "661     2.0\n",
      "5377    0.0\n",
      "5203    0.0\n",
      "4168    1.0\n",
      "\n",
      "[5940 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:, 1:]\n",
    "Y = df.iloc[:, :1]\n",
    "\n",
    "# print(X.head)\n",
    "# print(Y.head)\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dcc06b",
   "metadata": {},
   "source": [
    "## Using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bc5e8c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99747475 0.99747475 0.99747475 0.9983165  0.99915825]\n",
      "Cross Validation accuracy using Decision Tree 0.997979797979798\n",
      "Accuracy using Decision Tree = 0.9964225589225589\n",
      "      class\n",
      "6034    0.0\n",
      "940     2.0\n",
      "4267    1.0\n",
      "2148    2.0\n",
      "2259    1.0\n",
      "4019    1.0\n",
      "3188    1.0\n",
      "1914    2.0\n",
      "408     2.0\n",
      "1572    2.0\n",
      "[0. 2. 1. 2. 1. 1. 1. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "dtree_cv = DecisionTreeClassifier(criterion = 'entropy', random_state = 30)\n",
    "\n",
    "scores_dtree = cross_val_score(dtree_cv, X, Y, cv = 5, scoring = 'accuracy')\n",
    "print(scores_dtree)\n",
    "print(\"Cross Validation accuracy using Decision Tree\",scores_dtree.mean())\n",
    "\n",
    "dtree = DecisionTreeClassifier(criterion = 'entropy', random_state = 30)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.80, random_state = 30)\n",
    "\n",
    "dtree.fit(X_train, Y_train)\n",
    "Y_pred_dtree = dtree.predict(X_test)\n",
    "\n",
    "print(\"Accuracy using Decision Tree =\", accuracy_score(Y_test, Y_pred_dtree))\n",
    "\n",
    "print(Y_test[:10])\n",
    "\n",
    "print(Y_pred_dtree[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e61f65e",
   "metadata": {},
   "source": [
    "## Using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ae2d1569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.376623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>-0.337662</td>\n",
       "      <td>0.162338</td>\n",
       "      <td>-0.337662</td>\n",
       "      <td>0.279221</td>\n",
       "      <td>-0.253247</td>\n",
       "      <td>-0.045455</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.740260</td>\n",
       "      <td>-0.311688</td>\n",
       "      <td>-0.006494</td>\n",
       "      <td>-0.259740</td>\n",
       "      <td>-0.103896</td>\n",
       "      <td>-0.233766</td>\n",
       "      <td>-0.149351</td>\n",
       "      <td>-0.311688</td>\n",
       "      <td>0.064935</td>\n",
       "      <td>-0.168831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.127273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103030</td>\n",
       "      <td>-0.218182</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>-0.060606</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>-0.024242</td>\n",
       "      <td>-0.024242</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.630303</td>\n",
       "      <td>-0.218182</td>\n",
       "      <td>-0.024242</td>\n",
       "      <td>-0.187879</td>\n",
       "      <td>-0.145455</td>\n",
       "      <td>-0.157576</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.672727</td>\n",
       "      <td>0.357576</td>\n",
       "      <td>-0.084848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.198718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.019231</td>\n",
       "      <td>-0.205128</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>-0.134615</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>-0.108974</td>\n",
       "      <td>-0.096154</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.698718</td>\n",
       "      <td>-0.217949</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>-0.230769</td>\n",
       "      <td>-0.108974</td>\n",
       "      <td>-0.224359</td>\n",
       "      <td>-0.198718</td>\n",
       "      <td>-0.634615</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.243590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.346405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.124183</td>\n",
       "      <td>-0.326797</td>\n",
       "      <td>0.241830</td>\n",
       "      <td>-0.274510</td>\n",
       "      <td>0.346405</td>\n",
       "      <td>-0.137255</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.738562</td>\n",
       "      <td>-0.261438</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>-0.261438</td>\n",
       "      <td>-0.104575</td>\n",
       "      <td>-0.202614</td>\n",
       "      <td>-0.163399</td>\n",
       "      <td>-0.117647</td>\n",
       "      <td>-0.150327</td>\n",
       "      <td>-0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.271605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.117284</td>\n",
       "      <td>-0.265432</td>\n",
       "      <td>0.080247</td>\n",
       "      <td>-0.228395</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>-0.141975</td>\n",
       "      <td>-0.086420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.808642</td>\n",
       "      <td>-0.234568</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>-0.197531</td>\n",
       "      <td>-0.080247</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.129630</td>\n",
       "      <td>-0.524691</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.012346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class         1    2         3         4         5         6         7  \\\n",
       "2413    1.0 -0.376623  0.0 -0.142857 -0.337662  0.162338 -0.337662  0.279221   \n",
       "1047    2.0 -0.127273  0.0  0.103030 -0.218182  0.345455 -0.060606  0.272727   \n",
       "1385    2.0 -0.198718  0.0 -0.019231 -0.205128  0.211538 -0.134615  0.282051   \n",
       "4084    1.0 -0.346405  0.0 -0.124183 -0.326797  0.241830 -0.274510  0.346405   \n",
       "1965    2.0 -0.271605  0.0 -0.117284 -0.265432  0.080247 -0.228395  0.172840   \n",
       "\n",
       "             8         9  ...        36        37        38        39  \\\n",
       "2413 -0.253247 -0.045455  ... -0.740260 -0.311688 -0.006494 -0.259740   \n",
       "1047 -0.024242 -0.024242  ... -0.630303 -0.218182 -0.024242 -0.187879   \n",
       "1385 -0.108974 -0.096154  ... -0.698718 -0.217949  0.006410 -0.230769   \n",
       "4084 -0.137255  0.019608  ... -0.738562 -0.261438  0.006536 -0.261438   \n",
       "1965 -0.141975 -0.086420  ... -0.808642 -0.234568  0.018519 -0.197531   \n",
       "\n",
       "            40        41        42        43        44        45  \n",
       "2413 -0.103896 -0.233766 -0.149351 -0.311688  0.064935 -0.168831  \n",
       "1047 -0.145455 -0.157576 -0.200000 -0.672727  0.357576 -0.084848  \n",
       "1385 -0.108974 -0.224359 -0.198718 -0.634615  0.250000 -0.243590  \n",
       "4084 -0.104575 -0.202614 -0.163399 -0.117647 -0.150327 -0.111111  \n",
       "1965 -0.080247 -0.166667 -0.129630 -0.524691  0.037037  0.012346  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = 'model/gesture_classifier/gesture_train_akshay.csv'\n",
    "#dataset = 'model/gesture_classifier/gesture_train_kailash.csv'\n",
    "\n",
    "column_names = ['class', '1', '2', '3', '4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45']\n",
    "\n",
    "X_column_names = ['1', '2', '3', '4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45']\n",
    "\n",
    "df = pd.read_csv(dataset, header = None, names=column_names)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Shuffling the dataset\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# df = df.dropna(how='any', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d8407d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 3-NN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1333\n",
      "         1.0       1.00      1.00      1.00      1672\n",
      "         2.0       1.00      1.00      1.00      1747\n",
      "\n",
      "    accuracy                           1.00      4752\n",
      "   macro avg       1.00      1.00      1.00      4752\n",
      "weighted avg       1.00      1.00      1.00      4752\n",
      "\n",
      "Confusion Matrix\n",
      "[[1328    2    3]\n",
      " [   4 1668    0]\n",
      " [   0    1 1746]]\n",
      "\n",
      " Accuracy\n",
      "0.997895622895623\n",
      "Using 3-NN after 5-fold cross-validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neighbors\\_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neighbors\\_classification.py\", line 233, in fit\n    return self._fit(X, y)\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neighbors\\_base.py\", line 456, in _fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n    _assert_all_finite(\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nKNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[0;32m     21\u001b[0m knn_cv \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mknn_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscores: \u001b[39m\u001b[38;5;124m'\u001b[39m, scores)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean score: \u001b[39m\u001b[38;5;124m'\u001b[39m, scores\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:328\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    309\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    311\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[1;32m--> 328\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neighbors\\_classification.py\", line 233, in fit\n    return self._fit(X, y)\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\neighbors\\_base.py\", line 456, in _fit\n    X, y = self._validate_data(\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\", line 622, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py\", line 1146, in check_X_y\n    X = check_array(\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py\", line 957, in check_array\n    _assert_all_finite(\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py\", line 122, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py\", line 171, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nKNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "print(\"Using 3-NN\")\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "print(classification_report(Y_test,predictions))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(Y_test,predictions))\n",
    "print(\"\\n Accuracy\")\n",
    "print(accuracy_score(Y_test,predictions))\n",
    "\n",
    "# k (5)- fold method for training and testing split and check the difference in performance of 3-NN¶\n",
    "\n",
    "print(\"Using 3-NN after 5-fold cross-validation\")\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "knn_cv = KNeighborsClassifier(n_neighbors=3, metric = 'euclidean')\n",
    "scores = cross_val_score(knn_cv, X, Y, cv=5, scoring='accuracy')\n",
    "print('scores: ', scores)\n",
    "print('mean score: ', scores.mean())\n",
    "\n",
    "# Normalize the dataset and apply 3-NN using both euclidean and manhattan distance\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "for col in df.columns[:-1]:\n",
    "    df[col] = (df[col]-df[col].min())/(df[col].max()-df[col].min())\n",
    "\n",
    "X = df[df.columns[:-1]] # Selecting the independent variables\n",
    "Y=df[df.columns[len(df.columns)-1]] # selecting only the target lableled column\n",
    "\n",
    "knn_cv_euclidean = KNeighborsClassifier(n_neighbors=3, metric = 'euclidean')\n",
    "scores_euclidean = cross_val_score(knn_cv_euclidean, X, Y, cv=5, scoring='accuracy')\n",
    "print(\"scores euclidean: \", scores_euclidean)\n",
    "print('mean score: ', scores_euclidean.mean())\n",
    "\n",
    "knn_cv_manhattan = KNeighborsClassifier(n_neighbors=3, metric = 'manhattan')\n",
    "scores_manhattan = cross_val_score(knn_cv_manhattan, X, Y, cv=5, scoring='accuracy')\n",
    "print(\"scores manhattan: \", scores_manhattan)\n",
    "print('mean score: ', scores_manhattan.mean())\n",
    "\n",
    "\n",
    "# Plotting the accuracy for different values of Ks\n",
    "\n",
    "k_scores=[]\n",
    "\n",
    "for k in range(1,21):\n",
    "    knn_iter = KNeighborsClassifier(n_neighbors=k,metric = 'euclidean')\n",
    "    scores = cross_val_score(knn_iter, X, Y, cv=5, scoring='accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "    print(k,' scores: ', k_scores)\n",
    "\n",
    "    \n",
    "#### Write your answer here ####\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "k_range = list(range(1, 21))\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-Validated Accuracy')\n",
    "\n",
    "print('maximum score: ', max(k_scores))\n",
    "print('Best K value: ', k_scores.index(max(k_scores))+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ef84c3",
   "metadata": {},
   "source": [
    "## Using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db390fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      1328\n",
      "         1.0       0.99      0.99      0.99      1668\n",
      "         2.0       0.98      1.00      0.99      1756\n",
      "\n",
      "    accuracy                           0.99      4752\n",
      "   macro avg       0.99      0.99      0.99      4752\n",
      "weighted avg       0.99      0.99      0.99      4752\n",
      "\n",
      "Confusion Matrix\n",
      "[[1306   11   11]\n",
      " [   7 1643   18]\n",
      " [   0    7 1749]]\n",
      "\n",
      " Accuracy\n",
      "0.9886363636363636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agola\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# import Classifier library\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Call the Classifier\n",
    "nb=GaussianNB()\n",
    "\n",
    "predictions = nb.fit(X_train, Y_train).predict(X_test)\n",
    "\n",
    "print(\"Number of mislabeled points: \")\n",
    "#(X_test.shape[0], (Y_test != predictions).sum())\n",
    "\n",
    "\n",
    "predictions = nb.predict(X_test)\n",
    "\n",
    "# Calculate and print confusion matrix and other performance measures (Refer previous labsheet)\n",
    "\n",
    "print(classification_report(Y_test,predictions))\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(Y_test,predictions))\n",
    "print(\"\\n Accuracy\")\n",
    "print(accuracy_score(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec262502",
   "metadata": {},
   "source": [
    "## Using Bagging classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186db0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaggingClassifier(base_estimator = dtree, n_estimators = 5, random_state = 30)\n",
    "\n",
    "scores_model = cross_val_score(model, X, Y, cv = 5, scoring = 'accuracy')\n",
    "print(scores_model)\n",
    "print(\"Mean Ensemble Cross Validation accuracy by manipulating dataset\",scores_model.mean())\n",
    "model = model.fit(X_train, Y_train)\n",
    "Y_pred_model = model.predict(X_test)\n",
    "\n",
    "print(\"Ensemble Accuracy by manipulating dataset =\", accuracy_score(Y_test, Y_pred_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de62aa0",
   "metadata": {},
   "source": [
    "## Using Different Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0155768d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94321429 0.945      0.94142857 0.94821429 0.94678571]\n",
      "Mean Cross Validation accuracy using Bagging by manipulating classifiers 0.9449285714285713\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This VotingClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(scores)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Cross Validation accuracy using Bagging by manipulating classifiers\u001b[39m\u001b[38;5;124m\"\u001b[39m,scores\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m---> 20\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mvoting_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy by manipulating classifiers =\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(Y_test, Y_pred))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py:339\u001b[0m, in \u001b[0;36mVotingClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;124;03m\"\"\"Predict class labels for X.\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \n\u001b[0;32m    329\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m        Predicted class labels.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoting \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoft\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    341\u001b[0m         maj \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_proba(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1222\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1217\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1218\u001b[0m         v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(estimator) \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1219\u001b[0m     ]\n\u001b[0;32m   1221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This VotingClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# Question 2\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "dt_entropy = DecisionTreeClassifier(criterion = 'gini', random_state = 30)\n",
    "k3 = KNeighborsClassifier(n_neighbors = 3, metric = 'euclidean')\n",
    "k5_euclidean = KNeighborsClassifier(n_neighbors = 5, metric = 'euclidean')\n",
    "k5_manhattan = KNeighborsClassifier(n_neighbors = 5, metric = 'manhattan')\n",
    "nb = GaussianNB()\n",
    "\n",
    "voting_clf = VotingClassifier(estimators = [('DT', dt_entropy), ('K3' ,k3), ('k5E', k5_euclidean), ('K5M', k5_manhattan), ('NB', nb)], voting = 'hard')\n",
    "\n",
    "#voting_clf.fit(X_train, Y_train)\n",
    "\n",
    "scores = cross_val_score(voting_clf, X, Y, cv = 5, scoring = 'accuracy')\n",
    "\n",
    "print(scores)\n",
    "# print(\"Mean Cross Validation accuracy using Bagging by manipulating classifiers\",scores.mean())\n",
    "\n",
    "# Y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# print(\"Accuracy by manipulating classifiers =\", accuracy_score(Y_test, Y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3273f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "vector = []\n",
    "\n",
    "for i in range(5):\n",
    "    v = np.random.choice(np.arange(1, 17),10, replace = False)\n",
    "    vector.append(v)\n",
    "\n",
    "\n",
    "df1 = df.loc[:,vector[0]]\n",
    "df2 = df.loc[:,vector[1]]\n",
    "df3 = df.loc[:,vector[2]]\n",
    "df4 = df.loc[:,vector[3]]\n",
    "df5 = df.loc[:,vector[4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c40cc7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=30)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = df1[df1.columns[0:]]\n",
    "Y1 = df[df.columns[0]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X1, Y1, test_size = 0.30, random_state = 30)\n",
    "\n",
    "\n",
    "dtree1 = DecisionTreeClassifier(criterion = 'entropy', random_state = 30)\n",
    "dtree1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22a78def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = df2[df2.columns[0:]]\n",
    "Y2 = df[df.columns[0]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X2, Y2, test_size = 0.30, random_state = 30)\n",
    "\n",
    "\n",
    "dtree2 = DecisionTreeClassifier(criterion = 'entropy', random_state = 30)\n",
    "dtree2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df9873c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3 = df3[df3.columns[0:]]\n",
    "Y3 = df[df.columns[0]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X3, Y3, test_size = 0.30, random_state = 30)\n",
    "\n",
    "\n",
    "dtree3 = DecisionTreeClassifier(criterion = 'entropy', random_state = 30)\n",
    "dtree3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec30b943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=30)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4 = df4[df4.columns[0:]]\n",
    "Y4 = df[df.columns[0]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X4, Y4, test_size = 0.30, random_state = 30)\n",
    "\n",
    "\n",
    "dtree4 = DecisionTreeClassifier(criterion = 'entropy', random_state = 30)\n",
    "dtree4.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcdfcb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=30)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X5 = df5[df5.columns[0:]]\n",
    "Y5 = df[df.columns[0]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X5, Y5, test_size = 0.30, random_state = 30)\n",
    "\n",
    "\n",
    "dtree5 = DecisionTreeClassifier(criterion = 'entropy', random_state = 30)\n",
    "dtree5.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a50ae40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.865      0.86964286 0.85214286 0.86       0.87      ]\n",
      "Mean Ensemble Cross Validation by manipulating features = 0.8633571428571427\n",
      "Ensemble Accuracy using by manipulating features = 0.8651666666666666\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30, random_state = 30)\n",
    "\n",
    "clf = VotingClassifier(estimators = [('DT1', dtree1), ('DT2' ,dtree2), ('DT3', dtree3), ('DT4', dtree4), ('DT5', dtree5)], voting = 'hard')\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X_train, Y_train, cv = 5, scoring = 'accuracy')\n",
    "\n",
    "print(scores)\n",
    "print(\"Mean Ensemble Cross Validation by manipulating features =\",scores.mean())\n",
    "\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Ensemble Accuracy using by manipulating features =\", accuracy_score(Y_test, Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b201c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "\n",
    "vector = []\n",
    "\n",
    "for i in range(5):\n",
    "    v = np.random.choice(np.arange(1, 26),13, replace = False)\n",
    "    vector.append(v)\n",
    "\n",
    "\n",
    "df1 = df.copy (deep = True)\n",
    "df2 = df.copy (deep = True)\n",
    "df3 = df.copy (deep = True)\n",
    "df4 = df.copy (deep = True)\n",
    "df5 = df.copy (deep = True)\n",
    "\n",
    "\n",
    "for row in range(df.shape[0]):\n",
    "    \n",
    "    col = ord(df.iloc[row, 0]) - 64\n",
    "    \n",
    "    if col in vector[0]:\n",
    "        df1.iloc[row, 0] = '1'\n",
    "    else:\n",
    "        df1.iloc[row, 0] = '0'\n",
    "    \n",
    "    if col in vector[1]:\n",
    "        df2.iloc[row, 0] = '1'\n",
    "    else:\n",
    "        df2.iloc[row, 0] = '0'\n",
    "    \n",
    "    \n",
    "    if col in vector[2]:\n",
    "        df3.iloc[row, 0] = '1'\n",
    "    else:\n",
    "        df3.iloc[row, 0] = '0'\n",
    "        \n",
    "    if col in vector[3]:\n",
    "        df4.iloc[row, 0] = '1'\n",
    "    else:\n",
    "        df4.iloc[row, 0] = '0'\n",
    "        \n",
    "    if col in vector[4]:\n",
    "        df5.iloc[row, 0] = '1'\n",
    "    else:\n",
    "        df5.iloc[row, 0] = '0'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25e81108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = df1[df1.columns[1:]]\n",
    "Y1 = df1[df1.columns[0]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X1, Y1, test_size = 0.30, random_state = 30)\n",
    "\n",
    "\n",
    "Dtree1 = DecisionTreeClassifier(criterion = 'entropy', random_state = 30)\n",
    "Dtree1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e879c230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = df2[df2.columns[1:]]\n",
    "Y2 = df2[df2.columns[0]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X2, Y2, test_size = 0.30, random_state = 30)\n",
    "\n",
    "\n",
    "Dtree2 = DecisionTreeClassifier(criterion = 'entropy', random_state = 30)\n",
    "Dtree2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77a3a755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=30)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3 = df3[df3.columns[1:]]\n",
    "Y3 = df3[df3.columns[0]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X3, Y3, test_size = 0.30, random_state = 30)\n",
    "\n",
    "\n",
    "Dtree3 = DecisionTreeClassifier(criterion = 'entropy', random_state = 30)\n",
    "Dtree3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52c84afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4 = df4[df4.columns[1:]]\n",
    "Y4 = df4[df4.columns[0]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X4, Y4, test_size = 0.30, random_state = 30)\n",
    "\n",
    "\n",
    "Dtree4 = DecisionTreeClassifier(criterion = 'entropy', random_state = 30)\n",
    "Dtree4.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc674074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=30)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X5 = df5[df5.columns[1:]]\n",
    "Y5 = df5[df5.columns[0]]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X5, Y5, test_size = 0.30, random_state = 30)\n",
    "\n",
    "\n",
    "Dtree5 = DecisionTreeClassifier(criterion = 'entropy', random_state = 30)\n",
    "Dtree5.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8221ffb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.865      0.86964286 0.85214286 0.86       0.87      ]\n",
      "Mean Ensemble Cross Validation by manipulating classes = 0.8633571428571427\n",
      "Ensemble Accuracy using by manipulating classes = 0.8651666666666666\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30, random_state = 30)\n",
    "\n",
    "clf2 = VotingClassifier(estimators = [('DT_1', Dtree1), ('DT_2' ,Dtree2), ('DT_3', Dtree3), ('DT_4', Dtree4), ('DT_5', Dtree5)], voting = 'hard')\n",
    "\n",
    "clf2.fit(X_train, Y_train)\n",
    "\n",
    "scores = cross_val_score(clf2, X_train, Y_train, cv = 5, scoring = 'accuracy')\n",
    "\n",
    "print(scores)\n",
    "print(\"Mean Ensemble Cross Validation by manipulating classes =\",scores.mean())\n",
    "\n",
    "Y_pred = clf2.predict(X_test)\n",
    "\n",
    "print(\"Ensemble Accuracy using by manipulating classes =\", accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59cb90f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Ensemble classifier by manipulating classifier performs best with accuracy of 94.9% .\n",
      "Ensemble classifiers by manipulating classes and manipulating features  perform with identical accuracy of 86.51% .\n",
      " The Ensemble classifier by manipulation of dataset obtained accuracy of 89.2%\n"
     ]
    }
   ],
   "source": [
    "# Question 5\n",
    "\n",
    "print(\"The Ensemble classifier by manipulating classifier performs best with accuracy of 94.9% .\")\n",
    "print(\"Ensemble classifiers by manipulating classes and manipulating features  perform with identical accuracy of 86.51% .\")\n",
    "print(\" The Ensemble classifier by manipulation of dataset obtained accuracy of 89.2%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea88b70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.865      0.86964286 0.85214286 0.86       0.87      ]\n",
      "Mean Ensemble Cross Validation by manipulating classes = 0.8633571428571427\n",
      "Ensemble Accuracy using by manipulating classes = 0.8651666666666666\n"
     ]
    }
   ],
   "source": [
    "Dtree1 = DecisionTreeClassifier(criterion = 'entropy', random_state = 30)\n",
    "Dtree2 = DecisionTreeClassifier(criterion = 'entropy', random_state = 30)\n",
    "Dtree3 = DecisionTreeClassifier(criterion = 'entropy', random_state = 30)\n",
    "Dtree4 = DecisionTreeClassifier(criterion = 'entropy', random_state = 30)\n",
    "Dtree5 = DecisionTreeClassifier(criterion = 'entropy', random_state = 30)\n",
    "\n",
    "clf2 = VotingClassifier(estimators = [('DT_1', Dtree1), ('DT_2' ,Dtree2), ('DT_3', Dtree3), ('DT_4', Dtree4), ('DT_5', Dtree5)], voting = 'hard')\n",
    "\n",
    "clf2.fit(X_train, Y_train)\n",
    "\n",
    "scores = cross_val_score(clf2, X_train, Y_train, cv = 5, scoring = 'accuracy')\n",
    "\n",
    "print(scores)\n",
    "print(\"Mean Ensemble Cross Validation by manipulating classes =\",scores.mean())\n",
    "\n",
    "Y_pred = clf2.predict(X_test)\n",
    "\n",
    "print(\"Ensemble Accuracy using by manipulating classes =\", accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59698208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2d74e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
